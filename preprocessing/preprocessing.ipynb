{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e07bb2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('MBTI 500.csv') # 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba0c9008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posts</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>know intj tool use interaction people excuse a...</td>\n",
       "      <td>INTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rap music ehh opp yeah know valid well know fa...</td>\n",
       "      <td>INTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>preferably p hd low except wew lad video p min...</td>\n",
       "      <td>INTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drink like wish could drink red wine give head...</td>\n",
       "      <td>INTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>space program ah bad deal meing freelance max ...</td>\n",
       "      <td>INTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106062</th>\n",
       "      <td>stay frustrate world life want take long nap w...</td>\n",
       "      <td>INFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106063</th>\n",
       "      <td>fizzle around time mention sure mistake thing ...</td>\n",
       "      <td>INFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106064</th>\n",
       "      <td>schedule modify hey w intp strong wing underst...</td>\n",
       "      <td>INFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106065</th>\n",
       "      <td>enfj since january busy schedule able spend li...</td>\n",
       "      <td>INFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106066</th>\n",
       "      <td>feel like men good problem tell parent want te...</td>\n",
       "      <td>INFP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106067 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    posts  type\n",
       "0       know intj tool use interaction people excuse a...  INTJ\n",
       "1       rap music ehh opp yeah know valid well know fa...  INTJ\n",
       "2       preferably p hd low except wew lad video p min...  INTJ\n",
       "3       drink like wish could drink red wine give head...  INTJ\n",
       "4       space program ah bad deal meing freelance max ...  INTJ\n",
       "...                                                   ...   ...\n",
       "106062  stay frustrate world life want take long nap w...  INFP\n",
       "106063  fizzle around time mention sure mistake thing ...  INFP\n",
       "106064  schedule modify hey w intp strong wing underst...  INFP\n",
       "106065  enfj since january busy schedule able spend li...  INFP\n",
       "106066  feel like men good problem tell parent want te...  INFP\n",
       "\n",
       "[106067 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36246f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=data['posts'] # text 전처리를 위해 text 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4f64bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL, HTML 형태 제거\n",
    "import re\n",
    "def remove_html(text):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',text)\n",
    "\n",
    "def remove_URL(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'',text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08cad683",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = []\n",
    "for i in text:\n",
    "    i=str(i)\n",
    "    i2=remove_html(i)\n",
    "    i3=remove_URL(i2)\n",
    "    text2.append(i3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a708597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영어 표현식만 사용\n",
    "text3 = []\n",
    "for i in text2:\n",
    "    i2= re.sub('[^a-zA-Z]', ' ', str(i))\n",
    "    text3.append(i2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "949c2f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#소문자화\n",
    "text4 = [i.lower() for i in text3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04a7d0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\BM\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b73ce8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punctuation = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d680990d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#스탑워드 및 구두점 제거\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "text5 = []\n",
    "for i in text4:\n",
    "    sentence = i.split()\n",
    "    s=[]\n",
    "    for j in sentence:\n",
    "        if j not in stop_words and j not in punctuation and len(j)>2:\n",
    "            s.append(j)\n",
    "    s = \" \".join(s)\n",
    "    text5.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8625468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()\n",
    "text7=[]\n",
    "for i in text5:\n",
    "    words=word_tokenize(i)\n",
    "    l_word=[]\n",
    "    for w in words:\n",
    "        word =lem.lemmatize(w)\n",
    "        l_word.append(word)\n",
    "    l = \" \".join(l_word)\n",
    "    text7.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16ca5732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 총 단어에서 1% 이상의 문서에만 등장한 단어만을 사용\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer=CountVectorizer(min_df=0.01) \n",
    "X=vectorizer.fit_transform(text7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71c3ca4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3771"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#단어는 총 3771개\n",
    "vocab= vectorizer.get_feature_names()\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "602a9567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "text_list=Series(data=text7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c848b27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame([text_list,data.type]).T\n",
    "df.columns=['text','type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c1c93ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>know intj tool use interaction people excuse a...</td>\n",
       "      <td>INTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rap music ehh opp yeah know valid well know fa...</td>\n",
       "      <td>INTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>preferably low except wew lad video mind good ...</td>\n",
       "      <td>INTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drink like wish could drink red wine give head...</td>\n",
       "      <td>INTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>space program bad deal meing freelance max see...</td>\n",
       "      <td>INTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106062</th>\n",
       "      <td>stay frustrate world life want take long nap w...</td>\n",
       "      <td>INFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106063</th>\n",
       "      <td>fizzle around time mention sure mistake thing ...</td>\n",
       "      <td>INFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106064</th>\n",
       "      <td>schedule modify hey intp strong wing understan...</td>\n",
       "      <td>INFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106065</th>\n",
       "      <td>enfj since january busy schedule able spend li...</td>\n",
       "      <td>INFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106066</th>\n",
       "      <td>feel like men good problem tell parent want te...</td>\n",
       "      <td>INFP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106067 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  type\n",
       "0       know intj tool use interaction people excuse a...  INTJ\n",
       "1       rap music ehh opp yeah know valid well know fa...  INTJ\n",
       "2       preferably low except wew lad video mind good ...  INTJ\n",
       "3       drink like wish could drink red wine give head...  INTJ\n",
       "4       space program bad deal meing freelance max see...  INTJ\n",
       "...                                                   ...   ...\n",
       "106062  stay frustrate world life want take long nap w...  INFP\n",
       "106063  fizzle around time mention sure mistake thing ...  INFP\n",
       "106064  schedule modify hey intp strong wing understan...  INFP\n",
       "106065  enfj since january busy schedule able spend li...  INFP\n",
       "106066  feel like men good problem tell parent want te...  INFP\n",
       "\n",
       "[106067 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "915eb7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict={}\n",
    "for index,word in enumerate(vocab):\n",
    "    vocab_dict[index]=word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3eeea68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'abandon',\n",
       " 1: 'ability',\n",
       " 2: 'able',\n",
       " 3: 'abortion',\n",
       " 4: 'absence',\n",
       " 5: 'absolute',\n",
       " 6: 'absolutely',\n",
       " 7: 'absorb',\n",
       " 8: 'abstract',\n",
       " 9: 'abstraction',\n",
       " 10: 'absurd',\n",
       " 11: 'abuse',\n",
       " 12: 'abusive',\n",
       " 13: 'academic',\n",
       " 14: 'accent',\n",
       " 15: 'accept',\n",
       " 16: 'acceptable',\n",
       " 17: 'acceptance',\n",
       " 18: 'access',\n",
       " 19: 'accident',\n",
       " 20: 'accidentally',\n",
       " 21: 'accommodate',\n",
       " 22: 'accomplish',\n",
       " 23: 'accomplishment',\n",
       " 24: 'accord',\n",
       " 25: 'accordingly',\n",
       " 26: 'account',\n",
       " 27: 'accuracy',\n",
       " 28: 'accurate',\n",
       " 29: 'accurately',\n",
       " 30: 'accuse',\n",
       " 31: 'achieve',\n",
       " 32: 'achievement',\n",
       " 33: 'acid',\n",
       " 34: 'acknowledge',\n",
       " 35: 'acquaintance',\n",
       " 36: 'acquire',\n",
       " 37: 'across',\n",
       " 38: 'act',\n",
       " 39: 'action',\n",
       " 40: 'active',\n",
       " 41: 'actively',\n",
       " 42: 'activity',\n",
       " 43: 'actor',\n",
       " 44: 'actual',\n",
       " 45: 'actually',\n",
       " 46: 'adapt',\n",
       " 47: 'add',\n",
       " 48: 'addict',\n",
       " 49: 'addiction',\n",
       " 50: 'addition',\n",
       " 51: 'additional',\n",
       " 52: 'additionally',\n",
       " 53: 'address',\n",
       " 54: 'adhd',\n",
       " 55: 'adhere',\n",
       " 56: 'adjust',\n",
       " 57: 'admire',\n",
       " 58: 'admit',\n",
       " 59: 'admittedly',\n",
       " 60: 'adopt',\n",
       " 61: 'adorable',\n",
       " 62: 'adore',\n",
       " 63: 'adu',\n",
       " 64: 'adus',\n",
       " 65: 'advance',\n",
       " 66: 'advantage',\n",
       " 67: 'adventure',\n",
       " 68: 'advertise',\n",
       " 69: 'advice',\n",
       " 70: 'advise',\n",
       " 71: 'advocate',\n",
       " 72: 'aer',\n",
       " 73: 'aernate',\n",
       " 74: 'aernative',\n",
       " 75: 'aesthetic',\n",
       " 76: 'affair',\n",
       " 77: 'affect',\n",
       " 78: 'affection',\n",
       " 79: 'affectionate',\n",
       " 80: 'affirmation',\n",
       " 81: 'afford',\n",
       " 82: 'afraid',\n",
       " 83: 'afternoon',\n",
       " 84: 'afterwards',\n",
       " 85: 'age',\n",
       " 86: 'agency',\n",
       " 87: 'agenda',\n",
       " 88: 'aggression',\n",
       " 89: 'aggressive',\n",
       " 90: 'agnostic',\n",
       " 91: 'ago',\n",
       " 92: 'agree',\n",
       " 93: 'agreement',\n",
       " 94: 'ahead',\n",
       " 95: 'ahh',\n",
       " 96: 'ahough',\n",
       " 97: 'aid',\n",
       " 98: 'aim',\n",
       " 99: 'air',\n",
       " 100: 'aka',\n",
       " 101: 'alarm',\n",
       " 102: 'albeit',\n",
       " 103: 'album',\n",
       " 104: 'alcohol',\n",
       " 105: 'algorithm',\n",
       " 106: 'alien',\n",
       " 107: 'alienate',\n",
       " 108: 'align',\n",
       " 109: 'alike',\n",
       " 110: 'alive',\n",
       " 111: 'allow',\n",
       " 112: 'almost',\n",
       " 113: 'alone',\n",
       " 114: 'along',\n",
       " 115: 'aloof',\n",
       " 116: 'alot',\n",
       " 117: 'alpha',\n",
       " 118: 'already',\n",
       " 119: 'alright',\n",
       " 120: 'also',\n",
       " 121: 'always',\n",
       " 122: 'amaze',\n",
       " 123: 'amazon',\n",
       " 124: 'ambition',\n",
       " 125: 'ambitious',\n",
       " 126: 'america',\n",
       " 127: 'american',\n",
       " 128: 'among',\n",
       " 129: 'amongst',\n",
       " 130: 'amount',\n",
       " 131: 'amp',\n",
       " 132: 'amuse',\n",
       " 133: 'analogy',\n",
       " 134: 'analyse',\n",
       " 135: 'analysis',\n",
       " 136: 'analytical',\n",
       " 137: 'analyze',\n",
       " 138: 'ancient',\n",
       " 139: 'anecdotal',\n",
       " 140: 'anecdote',\n",
       " 141: 'angel',\n",
       " 142: 'anger',\n",
       " 143: 'angle',\n",
       " 144: 'angry',\n",
       " 145: 'animal',\n",
       " 146: 'anime',\n",
       " 147: 'annoy',\n",
       " 148: 'annoyance',\n",
       " 149: 'another',\n",
       " 150: 'answer',\n",
       " 151: 'anti',\n",
       " 152: 'anticipate',\n",
       " 153: 'antisocial',\n",
       " 154: 'anxiety',\n",
       " 155: 'anxious',\n",
       " 156: 'anybody',\n",
       " 157: 'anymore',\n",
       " 158: 'anyone',\n",
       " 159: 'anything',\n",
       " 160: 'anytime',\n",
       " 161: 'anyway',\n",
       " 162: 'anyways',\n",
       " 163: 'anywhere',\n",
       " 164: 'aogether',\n",
       " 165: 'apart',\n",
       " 166: 'apartment',\n",
       " 167: 'apathetic',\n",
       " 168: 'apathy',\n",
       " 169: 'apologize',\n",
       " 170: 'apology',\n",
       " 171: 'app',\n",
       " 172: 'apparent',\n",
       " 173: 'apparently',\n",
       " 174: 'appeal',\n",
       " 175: 'appear',\n",
       " 176: 'appearance',\n",
       " 177: 'apple',\n",
       " 178: 'applicable',\n",
       " 179: 'application',\n",
       " 180: 'apply',\n",
       " 181: 'appreciate',\n",
       " 182: 'appreciation',\n",
       " 183: 'approach',\n",
       " 184: 'appropriate',\n",
       " 185: 'approval',\n",
       " 186: 'approve',\n",
       " 187: 'apps',\n",
       " 188: 'appy',\n",
       " 189: 'arbitrary',\n",
       " 190: 'archetype',\n",
       " 191: 'architecture',\n",
       " 192: 'area',\n",
       " 193: 'argue',\n",
       " 194: 'argument',\n",
       " 195: 'arise',\n",
       " 196: 'arm',\n",
       " 197: 'army',\n",
       " 198: 'around',\n",
       " 199: 'arrange',\n",
       " 200: 'arrive',\n",
       " 201: 'arrogance',\n",
       " 202: 'arrogant',\n",
       " 203: 'art',\n",
       " 204: 'article',\n",
       " 205: 'articulate',\n",
       " 206: 'artificial',\n",
       " 207: 'artist',\n",
       " 208: 'artistic',\n",
       " 209: 'as',\n",
       " 210: 'ashamed',\n",
       " 211: 'asian',\n",
       " 212: 'aside',\n",
       " 213: 'ask',\n",
       " 214: 'asleep',\n",
       " 215: 'aspect',\n",
       " 216: 'assert',\n",
       " 217: 'assertion',\n",
       " 218: 'assertive',\n",
       " 219: 'assessment',\n",
       " 220: 'asshole',\n",
       " 221: 'assign',\n",
       " 222: 'assignment',\n",
       " 223: 'associate',\n",
       " 224: 'association',\n",
       " 225: 'assume',\n",
       " 226: 'assumption',\n",
       " 227: 'assure',\n",
       " 228: 'astrology',\n",
       " 229: 'atheism',\n",
       " 230: 'atheist',\n",
       " 231: 'atleast',\n",
       " 232: 'atm',\n",
       " 233: 'atmosphere',\n",
       " 234: 'attach',\n",
       " 235: 'attachment',\n",
       " 236: 'attack',\n",
       " 237: 'attempt',\n",
       " 238: 'attend',\n",
       " 239: 'attention',\n",
       " 240: 'attitude',\n",
       " 241: 'attract',\n",
       " 242: 'attraction',\n",
       " 243: 'attractive',\n",
       " 244: 'attribute',\n",
       " 245: 'audience',\n",
       " 246: 'audio',\n",
       " 247: 'aughing',\n",
       " 248: 'aunt',\n",
       " 249: 'australia',\n",
       " 250: 'authentic',\n",
       " 251: 'authenticity',\n",
       " 252: 'author',\n",
       " 253: 'authoritarian',\n",
       " 254: 'authority',\n",
       " 255: 'autism',\n",
       " 256: 'autistic',\n",
       " 257: 'automatic',\n",
       " 258: 'automatically',\n",
       " 259: 'aux',\n",
       " 260: 'auxiliary',\n",
       " 261: 'available',\n",
       " 262: 'avatar',\n",
       " 263: 'average',\n",
       " 264: 'avoid',\n",
       " 265: 'avoidant',\n",
       " 266: 'awake',\n",
       " 267: 'award',\n",
       " 268: 'aware',\n",
       " 269: 'awareness',\n",
       " 270: 'away',\n",
       " 271: 'awesome',\n",
       " 272: 'awful',\n",
       " 273: 'awhile',\n",
       " 274: 'awkward',\n",
       " 275: 'awkwardness',\n",
       " 276: 'aww',\n",
       " 277: 'axis',\n",
       " 278: 'baby',\n",
       " 279: 'bachelor',\n",
       " 280: 'back',\n",
       " 281: 'background',\n",
       " 282: 'backwards',\n",
       " 283: 'bad',\n",
       " 284: 'badass',\n",
       " 285: 'badly',\n",
       " 286: 'bag',\n",
       " 287: 'bake',\n",
       " 288: 'balance',\n",
       " 289: 'ball',\n",
       " 290: 'ban',\n",
       " 291: 'band',\n",
       " 292: 'bang',\n",
       " 293: 'bank',\n",
       " 294: 'banter',\n",
       " 295: 'bar',\n",
       " 296: 'bare',\n",
       " 297: 'barely',\n",
       " 298: 'barrier',\n",
       " 299: 'base',\n",
       " 300: 'basic',\n",
       " 301: 'basically',\n",
       " 302: 'basis',\n",
       " 303: 'bass',\n",
       " 304: 'bastard',\n",
       " 305: 'bat',\n",
       " 306: 'bathroom',\n",
       " 307: 'battery',\n",
       " 308: 'battle',\n",
       " 309: 'beach',\n",
       " 310: 'bear',\n",
       " 311: 'beast',\n",
       " 312: 'beat',\n",
       " 313: 'beautiful',\n",
       " 314: 'beauty',\n",
       " 315: 'become',\n",
       " 316: 'bed',\n",
       " 317: 'bedroom',\n",
       " 318: 'beer',\n",
       " 319: 'beforehand',\n",
       " 320: 'befriend',\n",
       " 321: 'beg',\n",
       " 322: 'begin',\n",
       " 323: 'behave',\n",
       " 324: 'behavior',\n",
       " 325: 'behavioral',\n",
       " 326: 'behaviour',\n",
       " 327: 'behind',\n",
       " 328: 'belief',\n",
       " 329: 'believe',\n",
       " 330: 'bell',\n",
       " 331: 'belong',\n",
       " 332: 'bend',\n",
       " 333: 'beneficial',\n",
       " 334: 'benefit',\n",
       " 335: 'besides',\n",
       " 336: 'best',\n",
       " 337: 'bet',\n",
       " 338: 'beta',\n",
       " 339: 'betray',\n",
       " 340: 'beyond',\n",
       " 341: 'bias',\n",
       " 342: 'bible',\n",
       " 343: 'big',\n",
       " 344: 'bike',\n",
       " 345: 'bill',\n",
       " 346: 'billion',\n",
       " 347: 'binary',\n",
       " 348: 'bind',\n",
       " 349: 'binge',\n",
       " 350: 'biological',\n",
       " 351: 'biology',\n",
       " 352: 'bipolar',\n",
       " 353: 'bird',\n",
       " 354: 'birth',\n",
       " 355: 'birthday',\n",
       " 356: 'bit',\n",
       " 357: 'bitch',\n",
       " 358: 'bite',\n",
       " 359: 'bitter',\n",
       " 360: 'bizarre',\n",
       " 361: 'black',\n",
       " 362: 'blah',\n",
       " 363: 'blame',\n",
       " 364: 'blank',\n",
       " 365: 'blanket',\n",
       " 366: 'blast',\n",
       " 367: 'blend',\n",
       " 368: 'bless',\n",
       " 369: 'blind',\n",
       " 370: 'block',\n",
       " 371: 'blog',\n",
       " 372: 'blood',\n",
       " 373: 'blow',\n",
       " 374: 'blue',\n",
       " 375: 'blunt',\n",
       " 376: 'board',\n",
       " 377: 'boat',\n",
       " 378: 'body',\n",
       " 379: 'boil',\n",
       " 380: 'bold',\n",
       " 381: 'bomb',\n",
       " 382: 'bond',\n",
       " 383: 'bone',\n",
       " 384: 'bonus',\n",
       " 385: 'book',\n",
       " 386: 'boost',\n",
       " 387: 'boot',\n",
       " 388: 'border',\n",
       " 389: 'borderline',\n",
       " 390: 'bore',\n",
       " 391: 'boredom',\n",
       " 392: 'bos',\n",
       " 393: 'bot',\n",
       " 394: 'bother',\n",
       " 395: 'bottle',\n",
       " 396: 'bottom',\n",
       " 397: 'bounce',\n",
       " 398: 'boundary',\n",
       " 399: 'bout',\n",
       " 400: 'bowl',\n",
       " 401: 'box',\n",
       " 402: 'boy',\n",
       " 403: 'boyfriend',\n",
       " 404: 'brag',\n",
       " 405: 'brain',\n",
       " 406: 'brainstorm',\n",
       " 407: 'branch',\n",
       " 408: 'brand',\n",
       " 409: 'brave',\n",
       " 410: 'bread',\n",
       " 411: 'break',\n",
       " 412: 'breakdown',\n",
       " 413: 'breakfast',\n",
       " 414: 'breakup',\n",
       " 415: 'breath',\n",
       " 416: 'breathe',\n",
       " 417: 'breed',\n",
       " 418: 'bridge',\n",
       " 419: 'brief',\n",
       " 420: 'briefly',\n",
       " 421: 'briggs',\n",
       " 422: 'bright',\n",
       " 423: 'brilliant',\n",
       " 424: 'bring',\n",
       " 425: 'british',\n",
       " 426: 'bro',\n",
       " 427: 'broad',\n",
       " 428: 'brother',\n",
       " 429: 'brown',\n",
       " 430: 'browse',\n",
       " 431: 'brush',\n",
       " 432: 'brutal',\n",
       " 433: 'bsp',\n",
       " 434: 'btw',\n",
       " 435: 'bubble',\n",
       " 436: 'bubbly',\n",
       " 437: 'bud',\n",
       " 438: 'buddhism',\n",
       " 439: 'buddy',\n",
       " 440: 'budget',\n",
       " 441: 'bug',\n",
       " 442: 'bui',\n",
       " 443: 'build',\n",
       " 444: 'bullet',\n",
       " 445: 'bullshit',\n",
       " 446: 'bully',\n",
       " 447: 'bump',\n",
       " 448: 'bunch',\n",
       " 449: 'burden',\n",
       " 450: 'burn',\n",
       " 451: 'burst',\n",
       " 452: 'bury',\n",
       " 453: 'bus',\n",
       " 454: 'bush',\n",
       " 455: 'business',\n",
       " 456: 'busy',\n",
       " 457: 'butt',\n",
       " 458: 'butterfly',\n",
       " 459: 'button',\n",
       " 460: 'buy',\n",
       " 461: 'cafe',\n",
       " 462: 'caffeine',\n",
       " 463: 'cake',\n",
       " 464: 'calculate',\n",
       " 465: 'calculus',\n",
       " 466: 'california',\n",
       " 467: 'call',\n",
       " 468: 'calm',\n",
       " 469: 'camera',\n",
       " 470: 'camp',\n",
       " 471: 'campaign',\n",
       " 472: 'campus',\n",
       " 473: 'can',\n",
       " 474: 'canada',\n",
       " 475: 'cancel',\n",
       " 476: 'cancer',\n",
       " 477: 'candidate',\n",
       " 478: 'candy',\n",
       " 479: 'cant',\n",
       " 480: 'cap',\n",
       " 481: 'capability',\n",
       " 482: 'capable',\n",
       " 483: 'capacity',\n",
       " 484: 'capital',\n",
       " 485: 'capitalism',\n",
       " 486: 'capitalist',\n",
       " 487: 'capture',\n",
       " 488: 'car',\n",
       " 489: 'card',\n",
       " 490: 'care',\n",
       " 491: 'career',\n",
       " 492: 'careful',\n",
       " 493: 'carefully',\n",
       " 494: 'carl',\n",
       " 495: 'carry',\n",
       " 496: 'case',\n",
       " 497: 'cash',\n",
       " 498: 'cast',\n",
       " 499: 'casual',\n",
       " 500: 'casually',\n",
       " 501: 'cat',\n",
       " 502: 'catch',\n",
       " 503: 'categorize',\n",
       " 504: 'category',\n",
       " 505: 'cater',\n",
       " 506: 'catholic',\n",
       " 507: 'cause',\n",
       " 508: 'cautious',\n",
       " 509: 'cave',\n",
       " 510: 'cease',\n",
       " 511: 'celebrate',\n",
       " 512: 'celebrity',\n",
       " 513: 'cell',\n",
       " 514: 'cent',\n",
       " 515: 'center',\n",
       " 516: 'central',\n",
       " 517: 'century',\n",
       " 518: 'certain',\n",
       " 519: 'certainly',\n",
       " 520: 'certainty',\n",
       " 521: 'chain',\n",
       " 522: 'chair',\n",
       " 523: 'challenge',\n",
       " 524: 'chameleon',\n",
       " 525: 'chance',\n",
       " 526: 'change',\n",
       " 527: 'channel',\n",
       " 528: 'chaos',\n",
       " 529: 'chaotic',\n",
       " 530: 'chapter',\n",
       " 531: 'character',\n",
       " 532: 'characteristic',\n",
       " 533: 'charge',\n",
       " 534: 'charismatic',\n",
       " 535: 'charity',\n",
       " 536: 'charm',\n",
       " 537: 'chart',\n",
       " 538: 'chase',\n",
       " 539: 'chat',\n",
       " 540: 'cheap',\n",
       " 541: 'cheat',\n",
       " 542: 'check',\n",
       " 543: 'cheer',\n",
       " 544: 'cheese',\n",
       " 545: 'chemical',\n",
       " 546: 'chemistry',\n",
       " 547: 'chess',\n",
       " 548: 'chest',\n",
       " 549: 'chick',\n",
       " 550: 'chicken',\n",
       " 551: 'child',\n",
       " 552: 'childhood',\n",
       " 553: 'childish',\n",
       " 554: 'chill',\n",
       " 555: 'china',\n",
       " 556: 'chinese',\n",
       " 557: 'chip',\n",
       " 558: 'chocolate',\n",
       " 559: 'choice',\n",
       " 560: 'choose',\n",
       " 561: 'chore',\n",
       " 562: 'christ',\n",
       " 563: 'christian',\n",
       " 564: 'christianity',\n",
       " 565: 'christmas',\n",
       " 566: 'chronic',\n",
       " 567: 'chunk',\n",
       " 568: 'church',\n",
       " 569: 'cigarette',\n",
       " 570: 'circle',\n",
       " 571: 'circumstance',\n",
       " 572: 'cite',\n",
       " 573: 'citizen',\n",
       " 574: 'city',\n",
       " 575: 'civil',\n",
       " 576: 'civilization',\n",
       " 577: 'claim',\n",
       " 578: 'clarification',\n",
       " 579: 'clarify',\n",
       " 580: 'clarity',\n",
       " 581: 'clash',\n",
       " 582: 'class',\n",
       " 583: 'classic',\n",
       " 584: 'classical',\n",
       " 585: 'classify',\n",
       " 586: 'classmate',\n",
       " 587: 'clean',\n",
       " 588: 'clear',\n",
       " 589: 'clearly',\n",
       " 590: 'clever',\n",
       " 591: 'cliche',\n",
       " 592: 'click',\n",
       " 593: 'client',\n",
       " 594: 'climate',\n",
       " 595: 'climb',\n",
       " 596: 'cling',\n",
       " 597: 'clingy',\n",
       " 598: 'clinical',\n",
       " 599: 'clinton',\n",
       " 600: 'clip',\n",
       " 601: 'clock',\n",
       " 602: 'close',\n",
       " 603: 'closely',\n",
       " 604: 'closet',\n",
       " 605: 'clothe',\n",
       " 606: 'cloud',\n",
       " 607: 'club',\n",
       " 608: 'clue',\n",
       " 609: 'coach',\n",
       " 610: 'coast',\n",
       " 611: 'coat',\n",
       " 612: 'cod',\n",
       " 613: 'code',\n",
       " 614: 'coffee',\n",
       " 615: 'cognition',\n",
       " 616: 'cognitive',\n",
       " 617: 'coherent',\n",
       " 618: 'coin',\n",
       " 619: 'coincidence',\n",
       " 620: 'cold',\n",
       " 621: 'collapse',\n",
       " 622: 'colleague',\n",
       " 623: 'collect',\n",
       " 624: 'collection',\n",
       " 625: 'collective',\n",
       " 626: 'college',\n",
       " 627: 'color',\n",
       " 628: 'colour',\n",
       " 629: 'combat',\n",
       " 630: 'combination',\n",
       " 631: 'combine',\n",
       " 632: 'combo',\n",
       " 633: 'come',\n",
       " 634: 'comedy',\n",
       " 635: 'comfort',\n",
       " 636: 'comfortable',\n",
       " 637: 'comic',\n",
       " 638: 'command',\n",
       " 639: 'comment',\n",
       " 640: 'commit',\n",
       " 641: 'commitment',\n",
       " 642: 'common',\n",
       " 643: 'commonly',\n",
       " 644: 'communicate',\n",
       " 645: 'communication',\n",
       " 646: 'communism',\n",
       " 647: 'communist',\n",
       " 648: 'community',\n",
       " 649: 'company',\n",
       " 650: 'compare',\n",
       " 651: 'comparison',\n",
       " 652: 'compassion',\n",
       " 653: 'compassionate',\n",
       " 654: 'compatibility',\n",
       " 655: 'compatible',\n",
       " 656: 'compel',\n",
       " 657: 'compensate',\n",
       " 658: 'compete',\n",
       " 659: 'competent',\n",
       " 660: 'competition',\n",
       " 661: 'competitive',\n",
       " 662: 'complain',\n",
       " 663: 'complaint',\n",
       " 664: 'complement',\n",
       " 665: 'complete',\n",
       " 666: 'completely',\n",
       " 667: 'complex',\n",
       " 668: 'complexity',\n",
       " 669: 'complicate',\n",
       " 670: 'compliment',\n",
       " 671: 'component',\n",
       " 672: 'compose',\n",
       " 673: 'comprehend',\n",
       " 674: 'compromise',\n",
       " 675: 'computer',\n",
       " 676: 'con',\n",
       " 677: 'concentrate',\n",
       " 678: 'concentration',\n",
       " 679: 'concept',\n",
       " 680: 'conceptual',\n",
       " 681: 'concern',\n",
       " 682: 'concert',\n",
       " 683: 'concise',\n",
       " 684: 'conclude',\n",
       " 685: 'conclusion',\n",
       " 686: 'concrete',\n",
       " 687: 'condescend',\n",
       " 688: 'condition',\n",
       " 689: 'conduct',\n",
       " 690: 'confidence',\n",
       " 691: 'confident',\n",
       " 692: 'confirm',\n",
       " 693: 'confirmation',\n",
       " 694: 'conflict',\n",
       " 695: 'conform',\n",
       " 696: 'confront',\n",
       " 697: 'confrontation',\n",
       " 698: 'confrontational',\n",
       " 699: 'confuse',\n",
       " 700: 'confusion',\n",
       " 701: 'congrats',\n",
       " 702: 'congratulation',\n",
       " 703: 'connect',\n",
       " 704: 'connection',\n",
       " 705: 'conquer',\n",
       " 706: 'conscious',\n",
       " 707: 'consciously',\n",
       " 708: 'consciousness',\n",
       " 709: 'consensus',\n",
       " 710: 'consequence',\n",
       " 711: 'conservative',\n",
       " 712: 'consider',\n",
       " 713: 'considerate',\n",
       " 714: 'consideration',\n",
       " 715: 'consist',\n",
       " 716: 'consistency',\n",
       " 717: 'consistent',\n",
       " 718: 'consistently',\n",
       " 719: 'conspiracy',\n",
       " 720: 'constant',\n",
       " 721: 'constantly',\n",
       " 722: 'construct',\n",
       " 723: 'construction',\n",
       " 724: 'constructive',\n",
       " 725: 'consume',\n",
       " 726: 'contact',\n",
       " 727: 'contain',\n",
       " 728: 'contemplate',\n",
       " 729: 'content',\n",
       " 730: 'contest',\n",
       " 731: 'context',\n",
       " 732: 'continue',\n",
       " 733: 'contract',\n",
       " 734: 'contradict',\n",
       " 735: 'contradiction',\n",
       " 736: 'contradictory',\n",
       " 737: 'contrary',\n",
       " 738: 'contrast',\n",
       " 739: 'contribute',\n",
       " 740: 'contribution',\n",
       " 741: 'control',\n",
       " 742: 'controversial',\n",
       " 743: 'convenient',\n",
       " 744: 'convention',\n",
       " 745: 'conventional',\n",
       " 746: 'conversation',\n",
       " 747: 'converse',\n",
       " 748: 'convert',\n",
       " 749: 'convey',\n",
       " 750: 'conviction',\n",
       " 751: 'convince',\n",
       " 752: 'cook',\n",
       " 753: 'cool',\n",
       " 754: 'cop',\n",
       " 755: 'cope',\n",
       " 756: 'copy',\n",
       " 757: 'core',\n",
       " 758: 'corner',\n",
       " 759: 'corporate',\n",
       " 760: 'corporation',\n",
       " 761: 'correct',\n",
       " 762: 'correctly',\n",
       " 763: 'correlate',\n",
       " 764: 'correlation',\n",
       " 765: 'correspond',\n",
       " 766: 'corrupt',\n",
       " 767: 'cost',\n",
       " 768: 'couch',\n",
       " 769: 'could',\n",
       " 770: 'counsel',\n",
       " 771: 'counselor',\n",
       " 772: 'count',\n",
       " 773: 'counter',\n",
       " 774: 'countless',\n",
       " 775: 'country',\n",
       " 776: 'couple',\n",
       " 777: 'courage',\n",
       " 778: 'course',\n",
       " 779: 'court',\n",
       " 780: 'cousin',\n",
       " 781: 'cover',\n",
       " 782: 'coworker',\n",
       " 783: 'coworkers',\n",
       " 784: 'crack',\n",
       " 785: 'craft',\n",
       " 786: 'crap',\n",
       " 787: 'crappy',\n",
       " 788: 'crash',\n",
       " 789: 'crave',\n",
       " 790: 'crazy',\n",
       " 791: 'cream',\n",
       " 792: 'create',\n",
       " 793: 'creation',\n",
       " 794: 'creative',\n",
       " 795: 'creativity',\n",
       " 796: 'creator',\n",
       " 797: 'creature',\n",
       " 798: 'credit',\n",
       " 799: 'creep',\n",
       " 800: 'creepy',\n",
       " 801: 'crime',\n",
       " 802: 'criminal',\n",
       " 803: 'cringe',\n",
       " 804: 'cripple',\n",
       " 805: 'crisis',\n",
       " 806: 'criterion',\n",
       " 807: 'critical',\n",
       " 808: 'criticism',\n",
       " 809: 'criticize',\n",
       " 810: 'critique',\n",
       " 811: 'cross',\n",
       " 812: 'crowd',\n",
       " 813: 'cruel',\n",
       " 814: 'crush',\n",
       " 815: 'cry',\n",
       " 816: 'cuddle',\n",
       " 817: 'cue',\n",
       " 818: 'cup',\n",
       " 819: 'cure',\n",
       " 820: 'curiosity',\n",
       " 821: 'curious',\n",
       " 822: 'current',\n",
       " 823: 'currently',\n",
       " 824: 'curse',\n",
       " 825: 'curve',\n",
       " 826: 'customer',\n",
       " 827: 'cut',\n",
       " 828: 'cute',\n",
       " 829: 'cuural',\n",
       " 830: 'cuure',\n",
       " 831: 'cuures',\n",
       " 832: 'cuz',\n",
       " 833: 'cycle',\n",
       " 834: 'cynical',\n",
       " 835: 'dad',\n",
       " 836: 'dae',\n",
       " 837: 'daily',\n",
       " 838: 'damage',\n",
       " 839: 'damn',\n",
       " 840: 'dance',\n",
       " 841: 'danger',\n",
       " 842: 'dangerous',\n",
       " 843: 'dare',\n",
       " 844: 'dark',\n",
       " 845: 'darkness',\n",
       " 846: 'data',\n",
       " 847: 'date',\n",
       " 848: 'daughter',\n",
       " 849: 'david',\n",
       " 850: 'day',\n",
       " 851: 'daydream',\n",
       " 852: 'dea',\n",
       " 853: 'dead',\n",
       " 854: 'deadline',\n",
       " 855: 'deal',\n",
       " 856: 'dear',\n",
       " 857: 'death',\n",
       " 858: 'debate',\n",
       " 859: 'debt',\n",
       " 860: 'decade',\n",
       " 861: 'decent',\n",
       " 862: 'decide',\n",
       " 863: 'decision',\n",
       " 864: 'declare',\n",
       " 865: 'decline',\n",
       " 866: 'decrease',\n",
       " 867: 'dedicate',\n",
       " 868: 'deem',\n",
       " 869: 'deep',\n",
       " 870: 'deeply',\n",
       " 871: 'defau',\n",
       " 872: 'defeat',\n",
       " 873: 'defend',\n",
       " 874: 'defense',\n",
       " 875: 'defensive',\n",
       " 876: 'define',\n",
       " 877: 'definite',\n",
       " 878: 'definitely',\n",
       " 879: 'definition',\n",
       " 880: 'degree',\n",
       " 881: 'delay',\n",
       " 882: 'delete',\n",
       " 883: 'deliberately',\n",
       " 884: 'delicious',\n",
       " 885: 'deliver',\n",
       " 886: 'delusion',\n",
       " 887: 'delusional',\n",
       " 888: 'delve',\n",
       " 889: 'demand',\n",
       " 890: 'democracy',\n",
       " 891: 'democratic',\n",
       " 892: 'demon',\n",
       " 893: 'demonstrate',\n",
       " 894: 'denial',\n",
       " 895: 'deny',\n",
       " 896: 'department',\n",
       " 897: 'depend',\n",
       " 898: 'dependent',\n",
       " 899: 'depress',\n",
       " 900: 'depression',\n",
       " 901: 'depressive',\n",
       " 902: 'depth',\n",
       " 903: 'derive',\n",
       " 904: 'describe',\n",
       " 905: 'description',\n",
       " 906: 'deserve',\n",
       " 907: 'design',\n",
       " 908: 'designer',\n",
       " 909: 'desire',\n",
       " 910: 'desk',\n",
       " 911: 'desperate',\n",
       " 912: 'desperately',\n",
       " 913: 'despise',\n",
       " 914: 'despite',\n",
       " 915: 'destroy',\n",
       " 916: 'destructive',\n",
       " 917: 'detach',\n",
       " 918: 'detail',\n",
       " 919: 'detect',\n",
       " 920: 'determine',\n",
       " 921: 'develop',\n",
       " 922: 'developer',\n",
       " 923: 'development',\n",
       " 924: 'device',\n",
       " 925: 'devil',\n",
       " 926: 'devote',\n",
       " 927: 'diagnose',\n",
       " 928: 'diagnosis',\n",
       " 929: 'dialogue',\n",
       " 930: 'dichotomy',\n",
       " 931: 'dick',\n",
       " 932: 'dictate',\n",
       " 933: 'die',\n",
       " 934: 'diet',\n",
       " 935: 'differ',\n",
       " 936: 'difference',\n",
       " 937: 'different',\n",
       " 938: 'differentiate',\n",
       " 939: 'differently',\n",
       " 940: 'difficu',\n",
       " 941: 'difficuies',\n",
       " 942: 'difficuy',\n",
       " 943: 'dig',\n",
       " 944: 'digital',\n",
       " 945: 'dimension',\n",
       " 946: 'dinner',\n",
       " 947: 'direct',\n",
       " 948: 'direction',\n",
       " 949: 'directly',\n",
       " 950: 'director',\n",
       " 951: 'dirty',\n",
       " 952: 'disagree',\n",
       " 953: 'disagreement',\n",
       " 954: 'disappear',\n",
       " 955: 'disappoint',\n",
       " 956: 'disappointment',\n",
       " 957: 'disaster',\n",
       " 958: 'discipline',\n",
       " 959: 'disclaimer',\n",
       " 960: 'discomfort',\n",
       " 961: 'disconnect',\n",
       " 962: 'discourage',\n",
       " 963: 'discover',\n",
       " 964: 'discovery',\n",
       " 965: 'discus',\n",
       " 966: 'discussion',\n",
       " 967: 'disease',\n",
       " 968: 'disgust',\n",
       " 969: 'dish',\n",
       " 970: 'dislike',\n",
       " 971: 'dismiss',\n",
       " 972: 'disorder',\n",
       " 973: 'display',\n",
       " 974: 'disprove',\n",
       " 975: 'disregard',\n",
       " 976: 'disrespect',\n",
       " 977: 'distance',\n",
       " 978: 'distant',\n",
       " 979: 'distinct',\n",
       " 980: 'distinction',\n",
       " 981: 'distinguish',\n",
       " 982: 'distract',\n",
       " 983: 'distraction',\n",
       " 984: 'distress',\n",
       " 985: 'disturb',\n",
       " 986: 'dive',\n",
       " 987: 'diverse',\n",
       " 988: 'divide',\n",
       " 989: 'divorce',\n",
       " 990: 'doctor',\n",
       " 991: 'document',\n",
       " 992: 'documentary',\n",
       " 993: 'dog',\n",
       " 994: 'dollar',\n",
       " 995: 'dom',\n",
       " 996: 'dominance',\n",
       " 997: 'dominant',\n",
       " 998: 'dominate',\n",
       " 999: 'doms',\n",
       " ...}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7bc2bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_df=pd.read_csv('vocab_dict.csv')\n",
    "# vocab=vocab_df['word'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "94b1ab7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106067/106067 [22:40<00:00, 77.98it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "new_list=[]\n",
    "for i in tqdm(df['text']):\n",
    "    sen = i.split()\n",
    "    temp=[]\n",
    "    for j in sen:\n",
    "        if j in vocab:\n",
    "            temp.append(j)\n",
    "    temp = \" \".join(temp)\n",
    "    new_list.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1508465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "text_list2=Series(data=new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "061a9313",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.DataFrame([text_list2,df.type]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8b4f258",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns=['text','type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "624c0e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.to_csv('preporcessing2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a4713d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict2= {v : k for k,v in vocab_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b911073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(vocab_dict,index=[0]).T.to_csv('vocab_dict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "26be4b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df2.loc[df2.text!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7754afd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어를 벡터화\n",
    "def vocab_numbering(word):\n",
    "    number = vocab_dict2.get(word)\n",
    "    return number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "18f99e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106066/106066 [00:15<00:00, 6759.41it/s]\n"
     ]
    }
   ],
   "source": [
    "num_list=[]\n",
    "for i in tqdm(df2.text):\n",
    "    sen = i.split()\n",
    "    new_sen=[]\n",
    "    for j in sen:\n",
    "        num= vocab_numbering(j)\n",
    "        new_sen.append(num)\n",
    "    \n",
    "    num_list.append(new_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "66a1cea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_list2=Series(data=num_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d1dd3e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features=len(vocab_dict) # 3771"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "09b0e4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=max(len(i) for i in num_list2) # 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3b6e8f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩과정. 모든 문장의 길이를 500으로 맞추기 위해, 500미만인 문장에 대해서 남은 칸에 0을 채워넣음\n",
    "for i in num_list2:\n",
    "    while len(i)< max_len:\n",
    "        i.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0375161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터로 변환된 단어 리스트(문장)를 텐서로 변환\n",
    "import torch\n",
    "tensor_num_list=torch.tensor(num_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cfdaff08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wordvalue</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1915, 1822, 3462, 3582, 1805, 2451, 1213, 153...</td>\n",
       "      <td>INTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2730, 2204, 3755, 1915, 3594, 3686, 1915, 126...</td>\n",
       "      <td>INTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2590, 2022, 1204, 3624, 2137, 1480, 2760, 92,...</td>\n",
       "      <td>INTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1022, 1977, 3719, 769, 1022, 2780, 3713, 1469...</td>\n",
       "      <td>INTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[3158, 2643, 283, 855, 1396, 2082, 2975, 1462,...</td>\n",
       "      <td>INTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106062</th>\n",
       "      <td>[198, 3444, 2113, 3314, 2155, 3415, 2193, 2758...</td>\n",
       "      <td>INFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106063</th>\n",
       "      <td>[2945, 2167, 1591, 1824, 3258, 3714, 3543, 243...</td>\n",
       "      <td>INFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106064</th>\n",
       "      <td>[1112, 3072, 456, 2945, 2, 3176, 1992, 3444, 2...</td>\n",
       "      <td>INFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106065</th>\n",
       "      <td>[1301, 1977, 2109, 1480, 2626, 3380, 2424, 365...</td>\n",
       "      <td>INFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106066</th>\n",
       "      <td>NaN</td>\n",
       "      <td>INFP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106067 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                wordvalue  type\n",
       "0       [1915, 1822, 3462, 3582, 1805, 2451, 1213, 153...  INTJ\n",
       "1       [2730, 2204, 3755, 1915, 3594, 3686, 1915, 126...  INTJ\n",
       "2       [2590, 2022, 1204, 3624, 2137, 1480, 2760, 92,...  INTJ\n",
       "3       [1022, 1977, 3719, 769, 1022, 2780, 3713, 1469...  INTJ\n",
       "4       [3158, 2643, 283, 855, 1396, 2082, 2975, 1462,...  INTJ\n",
       "...                                                   ...   ...\n",
       "106062  [198, 3444, 2113, 3314, 2155, 3415, 2193, 2758...  INFP\n",
       "106063  [2945, 2167, 1591, 1824, 3258, 3714, 3543, 243...  INFP\n",
       "106064  [1112, 3072, 456, 2945, 2, 3176, 1992, 3444, 2...  INFP\n",
       "106065  [1301, 1977, 2109, 1480, 2626, 3380, 2424, 365...  INFP\n",
       "106066                                                NaN  INFP\n",
       "\n",
       "[106067 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3=pd.DataFrame([num_list2,df.type]).T\n",
    "df3.columns=['wordvalue','type']\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bddc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16개의 클래스\n",
    "mbti_dict={0:'ENFJ',1:'ENFP',2:'ENTJ',3:'ENTP',4:'ESFJ',5:'ESFP',6:'ESTJ',7:'ESTP',8:'INFJ',9:'INFP',10:'INTJ',11:'INTP',12:'ISFJ',13:'ISFP',14:'ISFP',15:'ISTP'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b942fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key와 value를 바꿈\n",
    "mbti_dict2= {v : k for k,v in mbti_dict.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09478c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16개의 클래스 라벨링 함수\n",
    "def mbti_numbering(mbti):\n",
    "    number=mbti_dict2.get(mbti)\n",
    "    number=str(number)\n",
    "    return number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2171a7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2개의 클래스로 라벨링하는 함수\n",
    "def EI_binary(mbti):\n",
    "    if mbti[0] == 'E':\n",
    "        number = 0\n",
    "    else:\n",
    "        number = 1\n",
    "    return number\n",
    "\n",
    "def SN_binary(mbti):\n",
    "    if mbti[1] == 'S':\n",
    "        number = 0\n",
    "    else:\n",
    "        number = 1\n",
    "    return number\n",
    "\n",
    "def TF_binary(mbti):\n",
    "    if mbti[2] == 'T':\n",
    "        number = 0\n",
    "    else:\n",
    "        number = 1\n",
    "    return number\n",
    "\n",
    "def PJ_binary(mbti):\n",
    "    if mbti[3] == 'P':\n",
    "        number = 0\n",
    "    else:\n",
    "        number = 1\n",
    "    return number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4a77153d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#전처리된 데이터셋을 복사한 후 각각 분류 모델별로 나누어 저장\n",
    "import copy\n",
    "X_df_all = copy.deepcopy(df3)\n",
    "X_df_EI = copy.deepcopy(df3)\n",
    "X_df_SN = copy.deepcopy(df3)\n",
    "X_df_TF = copy.deepcopy(df3)\n",
    "X_df_PJ = copy.deepcopy(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2f118e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_all['type']=X_df_all['type'].apply(mbti_numbering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "07a30e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_EI['type']=X_df_EI['type'].apply(EI_binary)\n",
    "X_df_SN['type']=X_df_SN['type'].apply(SN_binary)\n",
    "X_df_TF['type']=X_df_TF['type'].apply(TF_binary)\n",
    "X_df_PJ['type']=X_df_PJ['type'].apply(PJ_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d754297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_EI.to_csv('MBTI_EI.csv')\n",
    "X_df_SN.to_csv('MBTI_SN.csv')\n",
    "X_df_TF.to_csv('MBTI_TF.csv')\n",
    "X_df_PJ.to_csv('MBTI_PJ.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe45b249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b7607170524edef308a25205d1485c0eb27f19e54993aafa822009cf0f56ab44"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
